import pickle

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from keras import backend as K
from keras.layers import Dense, Dropout
from keras.models import Sequential
from sklearn.model_selection import train_test_split

from src.Constant import final_training_set_csv, final_selected_feature_pick, model_save_json, model_save_h5
from keras.utils import plot_model


def recall(y_true, y_pred):
    """Recall metric.

    Only computes a batch-wise average of recall.

    Computes the recall, a metric for multi-label classification of
    how many relevant items are selected.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall


def precision(y_true, y_pred):
    """Precision metric.

    Only computes a batch-wise average of precision.

    Computes the precision, a metric for multi-label classification of
    how many selected items are relevant.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision


def f1(y_true, y_pred):
    precision_s = precision(y_true, y_pred)
    recall_s = recall(y_true, y_pred)
    return 2 * ((precision_s * recall_s) / (precision_s + recall_s + K.epsilon()))


def train_keras():
    print("---train_keras---")
    # 变量初始化,训练集循环30次
    nb_epoch = 50

    df = pd.read_csv(final_training_set_csv, index_col=0)

    df = df.sample(frac=1).reset_index(drop=True)

    with open(final_selected_feature_pick, 'rb') as handle:
        feature_columns = pickle.load(handle)

    # print(feature_columns)
    df_main = df[feature_columns]

    X = np.array(df_main)
    y = np.array(df['type'])

    # print(X.shape)
    # print(df[df['type'] == 1].count())

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

    print("X_train.shape:", X_train.shape)
    print(y_train.shape)
    # Keras实现了很多层，包括core核心层，Convolution卷积层、Pooling池化层
    model = Sequential([
        Dense(250, input_dim=X_train.shape[1], activation='relu'),
        # 0.4 的意思是让40%的神经元不工作，测试不用Dropout
        Dropout(0.4),
        Dense(200, activation='relu'),
        Dropout(0.4),
        Dense(150, activation='relu'),
        Dropout(0.4),
        Dense(100, activation='relu'),
        Dropout(0.4),
        Dense(1, activation='sigmoid')
    ])
    # 指定输入数据的尺寸,第一层需要接收关于其输入尺寸的信息,后面的各个层则可以自动的推导出中间数据的shape
    # 现在模型就会以尺寸为 (*, X_train.shape[1]) 的数组作为输入，
    # 其输出数组的尺寸为 (*, 250)

    # 9层神经网络

    # 打印模型
    model.summary()

    # 训练与评估
    # 编译模型
    """
    优化器 optimizer：它可以是现有优化器的字符串标识符，如 rmsprop 或 adagrad，也可以是 Optimizer 类的实例。
        RMSprop 全称 root mean square prop 算法，和动量方法一样都可以加快梯度下降速度。
    损失函数 loss：模型试图最小化的目标函数。它可以是现有损失函数的字符串标识符，如 categorical_crossentropy 或 mse，也可以是一个目标函数
        binary_cross_entropy是二分类的交叉熵
    评估标准 metrics：对于任何分类问题，metrics = ['accuracy']。评估标准可以是现有的标准的字符串标识符，也可以是自定义的评估标准函数。
    
    """
    model.compile(loss='binary_crossentropy',
                  optimizer='rmsprop',
                  metrics=['acc', precision, recall, f1])
    plot_model(model, to_file="model.png", show_shapes=True)
    # 迭代训练（注意这个地方要加入callbacks）
    training = model.fit(X_train, y_train, batch_size=32, epochs=nb_epoch, verbose=0, validation_data=(X_test, y_test))

    # 评估模型性能
    score = model.evaluate(X_test, y_test)
    print("score:", score)
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
    print('Test precision:', score[2])
    print('Test recall:', score[3])
    print('Test f1:', score[4])

    score = model.evaluate(X_train, y_train)
    print('train loss:', score[0])
    print('train accuracy:', score[1])

    model_json = model.to_json()
    with open(model_save_json, "w") as json_file:
        json_file.write(model_json)

    model.save_weights(model_save_h5)
    print("Model saved")

    # 绘图
    print(training.history.keys())
    plt.title('model loss/accuracy')

    plt.plot(training.history['acc'], "g")
    plt.xlabel('epoch')
    plt.ylabel('acc')
    plt.legend(['acc'], loc='lower right')

    # plt.plot(training.history['f1'], "y")
    # plt.ylabel('f1')
    # plt.legend(['f1'], loc='lower right')
    #
    # plt.plot(training.history['loss'], "r")
    # plt.ylabel('loss')
    # plt.legend(['loss'], loc='lower right')
    plt.show()
